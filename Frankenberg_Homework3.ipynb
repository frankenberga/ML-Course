{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elizabeth Avery Frankenberg; Machine Learning Homework 3; SVM Classification; February 10 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the necessary import statements\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Feature_3</th>\n",
       "      <th>Feature_4</th>\n",
       "      <th>Feature_5</th>\n",
       "      <th>Feature_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9070.02</td>\n",
       "      <td>20594.1000</td>\n",
       "      <td>-3429.72</td>\n",
       "      <td>94</td>\n",
       "      <td>163</td>\n",
       "      <td>1162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3747.51</td>\n",
       "      <td>1137.0000</td>\n",
       "      <td>-872.00</td>\n",
       "      <td>10</td>\n",
       "      <td>52</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2821.21</td>\n",
       "      <td>50.5575</td>\n",
       "      <td>-589.00</td>\n",
       "      <td>6</td>\n",
       "      <td>33</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10600.90</td>\n",
       "      <td>28167.8000</td>\n",
       "      <td>-2640.00</td>\n",
       "      <td>30</td>\n",
       "      <td>194</td>\n",
       "      <td>1521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13579.40</td>\n",
       "      <td>98062.5000</td>\n",
       "      <td>-5354.46</td>\n",
       "      <td>162</td>\n",
       "      <td>281</td>\n",
       "      <td>4061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature_1   Feature_2  Feature_3  Feature_4  Feature_5  Feature_6\n",
       "0    9070.02  20594.1000   -3429.72         94        163       1162\n",
       "1    3747.51   1137.0000    -872.00         10         52        101\n",
       "2    2821.21     50.5575    -589.00          6         33          5\n",
       "3   10600.90  28167.8000   -2640.00         30        194       1521\n",
       "4   13579.40  98062.5000   -5354.46        162        281       4061"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing the data and separating it into labels and features\n",
    "data = pd.read_csv(\"hw3_training_data.csv\")\n",
    "\n",
    "data_labels = data['Label']\n",
    "data_features = data[['Feature_1', 'Feature_2', 'Feature_3', 'Feature_4', 'Feature_5', 'Feature_6']]\n",
    "data_subset = data[['Feature_1', 'Feature_2', 'Feature_3', 'Feature_4', 'Feature_6']]\n",
    "\n",
    "data_features.head()\n",
    "\n",
    "#print data_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I created a train, test method which runs K fold cross validation on the SVC or NuSVC and returns the accuracy obtained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this method takes a subset and trains and tests it, returning its score\n",
    "def train_test(data_subset):\n",
    "    kf = KFold(n_splits = 10)\n",
    "    avg_accuracy = []\n",
    "\n",
    "    for train, test in kf.split(data_features):\n",
    "        labels_train, data_train = data_labels.iloc[train], data_subset[train]\n",
    "        labels_test, data_test = data_labels.iloc[test], data_subset[test]\n",
    "        clf = svm.NuSVC( cache_size=200, class_weight=None, coef0=0.0,\n",
    "        decision_function_shape='ovr', degree=3, gamma=.000001, kernel='rbf',\n",
    "        max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "        tol=0.001, verbose=False)\n",
    "        #norm_data = preprocessing.normalize(data_train, axis=1)\n",
    "        #clf = make_pipeline(StandardScaler(), svm.SVC())\n",
    "        clf.fit(data_train, labels_train) \n",
    "        avg_accuracy.append(clf.score(data_test, labels_test))\n",
    "    \n",
    "    avg = 0\n",
    "    for i in range (0, 10):\n",
    "        avg += avg_accuracy[i]\n",
    "    print avg/10\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To try and improve my parameters I created svc param selection which conducts GridSearchCV on a specified parameter matrix of Cs, gammas, and alternating kernels. I used this and the subsequent cell to determine the best parameters to use in my SVC. I ran this for both NuSVC and SVC--however, when I ran it for NuSVC I took out the parameter C as this is not included in the model. I also modified the kernel type, to be linear, sigmoid or polynomial. As these had long run times, I ran them each seperately and then compared the best linear parameters to best sigmoid to best polynomial to best rbf. I found that the rbf kernel provided the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this method does parameter selection using grid search\n",
    "def svc_param_selection(features, labels, nfolds):\n",
    "    Cs = [0.001, .01, .1, 1, 10, 100, 1000]\n",
    "    gammas = [0.00000001, 0.0000001, 0.000001, 0.00001, 0.0001, 0.001, 0.01, 1]\n",
    "    kernels = ['rbf'] #can switch this to 'linear', 'sigmoid', or 'polynomial' also, ran these all separately for runtime\n",
    "    params = {'C': Cs,'gamma' : gammas, 'kernel': kernels}\n",
    "    grid_search = GridSearchCV(svm.SVC(), params, cv=nfolds)\n",
    "    grid_search.fit(features, labels)\n",
    "    grid_search.best_params_\n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'rbf', 'gamma': 1e-06}\n"
     ]
    }
   ],
   "source": [
    "best_params = svc_param_selection(data_features, data_labels, nfolds=10)\n",
    "print best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best parameters for NuSVC were Kernel = rbf and Gamma = 1*10^-6. The best parameters for SVC were Kernel = rbf, C=1, Gamma = 1*10^-6. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method then goes through and tries a subset of features. I used this along with some manual attemps to find the best set of subsets possible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_all_features(data_features):\n",
    "    best_score= 0\n",
    "    features = None\n",
    "    score_dict = dict()\n",
    "    \n",
    "    data_features = data_features.abs()\n",
    "    \n",
    "    for i in range(0, 6):\n",
    "        for j in range(0, 6):\n",
    "            \n",
    "            if (j < i):\n",
    "                data_new = np.vstack(np.array(data_features.iloc[:,j:i]))\n",
    "        \n",
    "            elif (i == j):\n",
    "                data_new = np.vstack(np.array(data_features.iloc[:,i]))\n",
    "        \n",
    "            else:\n",
    "                data_new = np.vstack(np.array(data_features.iloc[:,i:j]))\n",
    "           \n",
    "            split_avg = train_test(data_new)\n",
    "            if (split_avg > best_score):\n",
    "                best_score = split_avg\n",
    "                features = data_new\n",
    "                print best_score\n",
    "    print (\"Best score:\", best_score)\n",
    "    print (\"Features:\", features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.59375\n",
      "0.7237499999999999\n",
      "0.7582142857142857\n",
      "0.7598214285714285\n",
      "('Best score:', 0.7598214285714285)\n",
      "('Features:', array([[9.07002e+03, 2.05941e+04, 3.42972e+03, 9.40000e+01],\n",
      "       [3.74751e+03, 1.13700e+03, 8.72000e+02, 1.00000e+01],\n",
      "       [2.82121e+03, 5.05575e+01, 5.89000e+02, 6.00000e+00],\n",
      "       ...,\n",
      "       [1.20230e+04, 7.34458e+04, 4.61000e+03, 3.00000e+01],\n",
      "       [2.94640e+04, 7.31255e+05, 1.46770e+04, 1.72000e+02],\n",
      "       [9.79249e+03, 5.15269e+04, 3.11000e+03, 2.80000e+01]]))\n"
     ]
    }
   ],
   "source": [
    "try_all_features(data_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7657142857142856"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test(np.array(data_subset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC:\n",
    "\n",
    "Feature 1, 2, 3, 4\n",
    "0.7594642857142857\n",
    "\n",
    "Feature 1, 2, 3, 6\n",
    "0.7608928571428571\n",
    "\n",
    "Feature 1, 2, 3, 4, 6\n",
    "0.7619642857142856\n",
    "\n",
    "NuSVC:\n",
    "Feature 1, 2, 3, 4, 6\n",
    "0.7657142857142856"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7655357142857142\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NuSVC(cache_size=200, class_weight=None, coef0=0.0,\n",
       "   decision_function_shape='ovr', degree=3, gamma=1e-06, kernel='rbf',\n",
       "   max_iter=-1, nu=0.5, probability=False, random_state=None,\n",
       "   shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test(np.array(data_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this method trains the model on a given file\n",
    "def train(filename):\n",
    "    \n",
    "    data = pd.read_csv(filename)\n",
    "    data_labels = data['Label']\n",
    "    data_features = data[['Feature_1', 'Feature_2', 'Feature_3', 'Feature_4', 'Feature_5', 'Feature_6']]\n",
    "    data_subset = data[['Feature_1', 'Feature_2', 'Feature_3', 'Feature_4', 'Feature_6']]\n",
    "    return train_test(np.array(data_subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this method does the prediction step and puts these values into a new file\n",
    "def predict_file(C, feature_test_filename, predict_test_filename):\n",
    "    test_data = pd.read_csv(feature_test_filename)\n",
    "    with open(predict_test_filename, 'w') as writeFile:\n",
    "        writer = csv.writer(writeFile) \n",
    "        data_features = test_data[['Feature_1', 'Feature_2', 'Feature_3', 'Feature_4', 'Feature_6']]\n",
    "        writer.writerow(['Feature_1', 'Feature_2', 'Feature_3', 'Feature_4', 'Feature_6', 'Label'])\n",
    "        X = np.array(data_features)\n",
    "        line = 0\n",
    "        while (line < 2400):\n",
    "            row = X[line]\n",
    "            prediction = predict(C, row)\n",
    "            row = np.append(row, prediction)\n",
    "            writer.writerow(row)\n",
    "            line += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(C, row):\n",
    "    row = row.reshape(1, -1)\n",
    "    prediction = C.predict(row)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two methods train the model clf using the parameters and type of SVC that I found to be the most accurate. They then predict the labels for the rows in the test file, subsequently outputting them to a predictions.csv. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7657142857142856\n"
     ]
    }
   ],
   "source": [
    "clf = train(\"hw3_training_data.csv\")\n",
    "predict_file(clf, \"hw3_test_data.csv\", \"hw3_predictions.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
