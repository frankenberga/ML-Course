{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elizabeth Avery Frankenberg; Machine Learning Homework 3; SVM Classification; February 10 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the necessary import statements\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB, ComplementNB, MultinomialNB, BernoulliNB \n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5\n",
       "1    4\n",
       "2    2\n",
       "3    4\n",
       "4    5\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing the data and separating it into labels and features\n",
    "data = pd.read_csv(\"CS74_HW4_training_set.csv\")\n",
    "\n",
    "data_labels = data['Label']\n",
    "data_features = data[['Feature_1', 'Feature_2', 'Feature_3', 'Feature_4', 'Feature_5', 'Feature_6']]\n",
    "data_subset = data[['Feature_2', 'Feature_3', 'Feature_4', 'Feature_5', 'Feature_6']]\n",
    "\n",
    "#if running multinomial then take the absolute value of all of the data points\n",
    "#data_features = data_features.abs()\n",
    "#data_features.head()\n",
    "data_labels.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I created a train, test method which runs K fold cross validation on the SVC, NuSVC, MultinomialNB(), ComplementNB() or GaussianNB() classifiers and returns the accuracy obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this method takes a subset and trains and tests it, returning its score\n",
    "def train_test(data_subset):\n",
    "    kf = KFold(n_splits = 10)\n",
    "    avg_accuracy = []\n",
    "#  kernel = 1.0 * RBF(1.0)\n",
    "#     clf = GaussianProcessClassifier(kernel=kernel, random_state=0, multi_class = \"one_vs_one\")\n",
    "    clf = svm.SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
    "        decision_function_shape='ovr', degree=3, gamma=.0000001, kernel='rbf',\n",
    "        max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "        tol=0.001, verbose=False)\n",
    "#     clf = clf = svm.NuSVC(nu= 0.5, cache_size=200, class_weight=None, coef0=0.0,\n",
    "#          decision_function_shape='ovr', degree=3, gamma=.0000001, kernel='rbf',\n",
    "#          max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "#          tol=0.001, verbose=False)\n",
    "    #clf = MultinomialNB()\n",
    "    #clf = GaussianNB()\n",
    "    #clf = ComplementNB()\n",
    "    for train, test in kf.split(data_features):\n",
    "        labels_train, data_train = data_labels.iloc[train], data_subset[train]\n",
    "        labels_test, data_test = data_labels.iloc[test], data_subset[test]\n",
    "        #norm_data = preprocessing.normalize(data_train, axis=1)\n",
    "        #clf = make_pipeline(StandardScaler(), svm.SVC())\n",
    "        clf.fit(data_train, labels_train) \n",
    "        avg_accuracy.append(clf.score(data_test, labels_test))\n",
    "    avg = 0\n",
    "    for i in range (0, 10):\n",
    "        avg += avg_accuracy[i]\n",
    "    #return avg/10\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6561111111111111"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test(np.array(data_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To try and improve my parameters I created two param selection methods; one that chooses the best parameters for SVC and one that chooses the best for NuSVC. They both conduct GridSearchCV on a specified parameter matrix of Cs, gammas, and alternating kernels for the SVM method and Nu's, gammas and alternating kernels for the NuSVM method. I used this and the subsequent cell to determine the best parameters to use for these two classifiers. I also modified the kernel type, to be linear, sigmoid or polynomial. As these had long run times, I ran them each seperately and then compared the best linear parameters to best sigmoid to best polynomial to best rbf. I found that the rbf kernel provided the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this method does parameter selection for svc using grid search\n",
    "def svc_param_selection(features, labels, nfolds):\n",
    "    Cs = [0.001, .01, .1, 1, 10, 100, 1000]\n",
    "    gammas = [0.00000001, 0.0000001, 0.000001, 0.00001, 0.0001, 0.001, 0.01, 1]\n",
    "    kernels = ['sigmoid'] #can switch this to 'linear', 'sigmoid', or 'polynomial' also, ran these all separately for runtime\n",
    "    params = {'C': Cs,'gamma' : gammas, 'kernel': kernels}\n",
    "    grid_search = GridSearchCV(svm.SVC(), params, cv=nfolds)\n",
    "    grid_search.fit(features, labels)\n",
    "    grid_search.best_params_\n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'sigmoid', 'C': 1, 'gamma': 1e-06}\n"
     ]
    }
   ],
   "source": [
    "best_params = svc_param_selection(data_features, data_labels, nfolds=10)\n",
    "print best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best parameters for SVM were:\n",
    "kernel = 'rbf', C = 1000, and gamma = 1*e^-7\n",
    "kernel = 'sigmoid', C = 1, and gamma = 1*e^-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this method does parameter selection for nusvc using grid search\n",
    "def nusvc_param_selection(features, labels, nfolds):\n",
    "    nus = [.01, .05, .1, .5, .7]\n",
    "    gammas = [0.00000001, 0.0000001, 0.000001, 0.00001, 0.0001, 0.001, 0.01, 1]\n",
    "    kernels = ['rbf'] #can switch this to 'linear', 'sigmoid', or 'polynomial' also, ran these all separately for runtime\n",
    "    params = {'nu': nus,'gamma' : gammas, 'kernel': kernels}\n",
    "    grid_search = GridSearchCV(svm.NuSVC(), params, cv=nfolds)\n",
    "    grid_search.fit(features, labels)\n",
    "    grid_search.best_params_\n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_params = nusvc_param_selection(data_features, data_labels, nfolds=10)\n",
    "print best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best parameters for NuSVM were:\n",
    "kernel = 'rbf', Nu = 0.1, and gamma = 1*e^-6 \n",
    "kernel = 'sigmoid', Nu = 0.5 and gamma = 1*e^-7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method then goes through and tries a subset of features. I used this along with some manual attemps to find the best set of subsets possible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_all_features(data_features):\n",
    "    best_score= 0\n",
    "    features = None\n",
    "    score_dict = dict()\n",
    "    \n",
    "    data_features = data_features.abs()\n",
    "    \n",
    "    for i in range(0, 6):\n",
    "        for j in range(0, 6):\n",
    "            \n",
    "            if (j < i):\n",
    "                data_new = np.vstack(np.array(data_features.iloc[:,j:i]))\n",
    "        \n",
    "            elif (i == j):\n",
    "                data_new = np.vstack(np.array(data_features.iloc[:,i]))\n",
    "        \n",
    "            else:\n",
    "                data_new = np.vstack(np.array(data_features.iloc[:,i:j]))\n",
    "           \n",
    "            split_avg = train_test(data_new)\n",
    "            if (split_avg > best_score):\n",
    "                best_score = split_avg\n",
    "                features = data_new\n",
    "                print best_score\n",
    "    print (\"Best score:\", best_score)\n",
    "    print (\"Features:\", features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22222222222222218\n",
      "0.23433333333333334\n",
      "0.26888888888888884\n",
      "0.2696666666666667\n",
      "0.3137777777777778\n",
      "('Best score:', 0.3137777777777778)\n",
      "('Features:', array([[3831.21,   76.  ,  172.  ],\n",
      "       [1834.2 ,   70.  ,  107.  ],\n",
      "       [4367.33,  114.  ,  205.  ],\n",
      "       ...,\n",
      "       [3454.87,   35.  ,  176.  ],\n",
      "       [9980.  ,   68.  ,  540.  ],\n",
      "       [3365.31,   39.  ,  174.  ]]))\n"
     ]
    }
   ],
   "source": [
    "try_all_features(data_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results from different tests:\n",
    "\n",
    "SVM with all features:\n",
    "0.65611111\n",
    "kernel = rbf\n",
    "C = 1000\n",
    "gamma = 1*e^-7\n",
    "\n",
    "0.24488888888888888\n",
    "kernel = sigmoid\n",
    "C = 1\n",
    "gamma = 1*e^-6\n",
    "\n",
    "NuSVM with all features:\n",
    "0.6252222\n",
    "kernel = rbf\n",
    "Nu = 0.1\n",
    "gamma = 1*e^-6\n",
    "\n",
    "0.27822222222222226\n",
    "kernel = sigmoid\n",
    "Nu - 0.5\n",
    "gamma = 1*e^-7\n",
    "\n",
    "NuSVM with subset of features:\n",
    "Features = 1-5\n",
    "0.6094444444444445\n",
    "kernel = rbf\n",
    "Nu = 0.1\n",
    "gamma = 1*e^-6\n",
    "\n",
    "Features 1-4, 6\n",
    "0.6201111111111111\n",
    "Nu = 0.1\n",
    "gamma = 1*e^-6\n",
    "\n",
    "Features 1-3, 5-6\n",
    "0.6091111111111112\n",
    "Nu = 0.1\n",
    "gamma = 1*e^-6\n",
    "\n",
    "Gaussian NB (with trying best feature subset):\n",
    "Feature 5\n",
    "0.28366\n",
    "\n",
    "Multinomial NB (with trying best feature subset and taking absolute value of values):\n",
    "Features 3-5\n",
    "0.2703333333333333\n",
    "\n",
    "Complement NB (with trying best features subset):\n",
    "Features 3-5\n",
    "0.3137777777777778"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this method trains the model on a given file\n",
    "def train(filename):\n",
    "    data = pd.read_csv(filename)\n",
    "    data_labels = data['Label']\n",
    "    data_features = data[['Feature_1', 'Feature_2', 'Feature_3', 'Feature_4', 'Feature_5', 'Feature_6']]\n",
    "    return train_test(np.array(data_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this method does the prediction step and puts these values into a new file\n",
    "def predict_file(C, feature_test_filename, predict_test_filename):\n",
    "    test_data = pd.read_csv(feature_test_filename)\n",
    "    with open(predict_test_filename, 'w') as writeFile:\n",
    "        writer = csv.writer(writeFile) \n",
    "        data_features = test_data[['Feature_1', 'Feature_2', 'Feature_3', 'Feature_4', 'Feature_5', 'Feature_6']]\n",
    "        writer.writerow(['Feature_1', 'Feature_2', 'Feature_3', 'Feature_4', 'Feature_5', 'Feature_6', 'Label'])\n",
    "        X = np.array(data_features)\n",
    "        line = 0\n",
    "        while (line < 2161):\n",
    "            row = X[line]\n",
    "            prediction = predict(C, row)\n",
    "            row = np.append(row, prediction)\n",
    "            writer.writerow(row)\n",
    "            line += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(C, row):\n",
    "    row = row.reshape(1, -1)\n",
    "    print row\n",
    "    prediction = C.predict(row)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two methods train the model clf using the parameters and type of SVC that I found to be the most accurate. They then predict the labels for the rows in the test file, subsequently outputting them to a predictions.csv. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = train(\"CS74_HW4_training_set.csv\")\n",
    "predict_file(clf, \"CS74_HW4_test_set.csv\", \"CS74_HW4_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
