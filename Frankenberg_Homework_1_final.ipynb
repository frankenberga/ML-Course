{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elizabeth Avery Frankenberg; \n",
    "Machine Learning; \n",
    "Homework 1: NB Classification; \n",
    "January 15 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"hw1_trainingset.csv\")\n",
    "\n",
    "data_labels = data['Label']\n",
    "data_features = data[['Feature_1', 'Feature_2', 'Feature_3', 'Feature_4', 'Feature_5', 'Feature_6']]\n",
    "data_subset = data[['Feature_1', 'Feature_2', 'Feature_4', 'Feature_5', 'Feature_6']]\n",
    "data_subset1 = data[['Feature_2', 'Feature_3', 'Feature_4', 'Feature_6']]\n",
    "#data_subset.head()\n",
    "\n",
    "#data_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading in the data I tried to determine which features were more important to include in the model training and fitting. First I used the VarianceThreshold feature selection method. From this measure we find no features changed and therefore were unable to eliminate the inclusion of any features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.43014e+03,  9.52978e+03, -2.45333e+03,  1.90000e+01,\n",
       "         1.23000e+02,  6.21000e+02],\n",
       "       [ 1.12564e+04,  5.04551e+04, -4.22000e+03,  1.80000e+01,\n",
       "         2.16000e+02,  2.67700e+03],\n",
       "       [ 1.30930e+04,  5.18971e+04, -2.88000e+03,  3.00000e+01,\n",
       "         2.34000e+02,  2.46400e+03],\n",
       "       ...,\n",
       "       [ 1.57935e+04,  2.16990e+05, -9.81900e+03,  4.40000e+01,\n",
       "         3.38000e+02,  8.32300e+03],\n",
       "       [ 8.78716e+03,  2.07786e+04, -3.47008e+03,  9.20000e+01,\n",
       "         1.63000e+02,  1.16200e+03],\n",
       "       [ 8.32240e+03,  1.22089e+04, -2.59259e+03,  8.30000e+01,\n",
       "         1.28000e+02,  6.93000e+02]])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "X = data_features\n",
    "sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "sel.fit_transform(X)\n",
    "#print X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I tried to use the SelectKBest feature selection algorithm. I ran this with different k values (from 1-5 because you can't include negative numbers in this test) it looks as though the features rank in this order of importance--excluding Feature 3 becuase it has negative numbers. I then used this ranking to test out different combinations of features in the training and testing.\n",
    "Best to worst: \n",
    "Feature 2\n",
    "Feature 6\n",
    "Feature 1\n",
    "Feature 5\n",
    "Feature 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "X, y = data_subset, data_labels\n",
    "X_new = SelectKBest(chi2, k=4).fit_transform(X, y)\n",
    "#print X_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I trained the classifier on all of the data to figure out which NB classifier (Bernoulli or Gaussian) I wanted to use and which set of features performed best. I tested these by using a method to calculate the accuracy of the predicted values. \n",
    "\n",
    "Here are some of the feature sets and accuracy scores that I obtained:\n",
    "\n",
    ".594821 with all features\n",
    "\n",
    ".59697 with features 1, 2, 4, 5, 6\n",
    "\n",
    ".598 with features 2, 6\n",
    "\n",
    ".599 with features 2, 3, 6\n",
    "\n",
    ".601 with features 2, 3, 4, 5, 6\n",
    "\n",
    ".608 with features 2, 3, 4, 6 \n",
    "\n",
    "After doing this I trained the classifier on all of the data looking at the difference between Bernoulli and Gaussian NB. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the classifier on all of the data\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "model_B = BernoulliNB()\n",
    "model_G = GaussianNB()\n",
    "#training, fitting and learning\n",
    "model_B.fit(data_subset, data_labels)\n",
    "model_G.fit(data_subset1, data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('accuracy', 0.6080357142857142)\n"
     ]
    }
   ],
   "source": [
    "#1 the predicted model\n",
    "predicted = model_G.predict(data_subset1)\n",
    "#the length of the target array\n",
    "lenTarArr = len(data_labels)\n",
    "correct = 0\n",
    "#for each element \n",
    "for i in range(lenTarArr):\n",
    "    #if the binary number at position i is equal to the item in that spot in the target array, then increment correct\n",
    "    if data_labels[i] == predicted[i]:\n",
    "        correct += 1\n",
    "#taking the number of correct values out of the total number\n",
    "print('accuracy', float(correct)/lenTarArr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I found that Gaussian performed better than Bernoulli but I wanted to check and see what Complement and Multinomial would do as well. Therefore, I made this function to calculate the accuracy with different features with different methods. I actually found that after doing the absolute value of the data set, so that there were no negative numbers, I was able to get a better accuracy with Multinomial NB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB, ComplementNB, MultinomialNB, BernoulliNB \n",
    "def try_all_features():\n",
    "    data = pd.read_csv(\"hw1_trainingset.csv\")\n",
    "    data_labels = data['Label']\n",
    "    data_features = data[['Feature_1', 'Feature_2', 'Feature_3', 'Feature_4', 'Feature_5', 'Feature_6']]\n",
    "    Y = np.array(data_labels)\n",
    "    best_score= 0\n",
    "    features = None\n",
    "    \n",
    "    #this transforms the data so there are negatives\n",
    "#     data_features = data_features.apply(lambda x:x+10000000)\n",
    "    data_features = data_features.abs()\n",
    "    \n",
    "    for i in range(0, 6):\n",
    "        for j in range(0, 6):\n",
    "            \n",
    "            if (j < i):\n",
    "                data_new = np.vstack(np.array(data_features.iloc[:,j:i]))\n",
    "        \n",
    "            elif (i == j):\n",
    "                data_new = np.vstack(np.array(data_features.iloc[:,i]))\n",
    "        \n",
    "            else:\n",
    "                data_new = np.vstack(np.array(data_features.iloc[:,i:j]))\n",
    "                \n",
    "        modelKFolds = MultinomialNB()\n",
    "\n",
    "        train_scores = []\n",
    "        test_scores = []\n",
    "        score = 0\n",
    "        kf = KFold(n_splits=10)\n",
    "        for train, test in kf.split(data_new):\n",
    "            x_train, y_train = data_new[train], Y[train]\n",
    "            x_test, y_test = data_new[test], Y[test]\n",
    "        \n",
    "            modelKFolds.fit(x_train, y_train)\n",
    "            y_pred = modelKFolds.predict(x_test)\n",
    "            score += metrics.accuracy_score(y_test, y_pred) /10\n",
    "            \n",
    "        if (score > best_score):\n",
    "            best_score = score\n",
    "            features = data_new\n",
    "            print \"highest accuracy %.4f\" %best_score \n",
    "            print features           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highest accuracy 0.5723\n",
      "[[7.43014e+03 9.52978e+03 2.45333e+03 1.90000e+01 1.23000e+02]\n",
      " [1.12564e+04 5.04551e+04 4.22000e+03 1.80000e+01 2.16000e+02]\n",
      " [1.30930e+04 5.18971e+04 2.88000e+03 3.00000e+01 2.34000e+02]\n",
      " ...\n",
      " [1.57935e+04 2.16990e+05 9.81900e+03 4.40000e+01 3.38000e+02]\n",
      " [8.78716e+03 2.07786e+04 3.47008e+03 9.20000e+01 1.63000e+02]\n",
      " [8.32240e+03 1.22089e+04 2.59259e+03 8.30000e+01 1.28000e+02]]\n",
      "highest accuracy 0.5786\n",
      "[[9.52978e+03 2.45333e+03 1.90000e+01 1.23000e+02]\n",
      " [5.04551e+04 4.22000e+03 1.80000e+01 2.16000e+02]\n",
      " [5.18971e+04 2.88000e+03 3.00000e+01 2.34000e+02]\n",
      " ...\n",
      " [2.16990e+05 9.81900e+03 4.40000e+01 3.38000e+02]\n",
      " [2.07786e+04 3.47008e+03 9.20000e+01 1.63000e+02]\n",
      " [1.22089e+04 2.59259e+03 8.30000e+01 1.28000e+02]]\n",
      "highest accuracy 0.6582\n",
      "[[2453.33   19.    123.  ]\n",
      " [4220.     18.    216.  ]\n",
      " [2880.     30.    234.  ]\n",
      " ...\n",
      " [9819.     44.    338.  ]\n",
      " [3470.08   92.    163.  ]\n",
      " [2592.59   83.    128.  ]]\n"
     ]
    }
   ],
   "source": [
    "try_all_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I got the best accuracy score with Multinomial NB of 0.6582 for an individual KFold and included Feature 3, 4, and 5.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After choosing the features I wanted to include, I then wrote the train and predict functions that implemented KFolds cross validation using MultinomialNB after transforming the values to be the absolute value. I decided to test out a few more variations when I actually ran this train method and was able to get a higher confidence score using Features 1, 3, 4 and 5. Here are these methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "def train(filename):\n",
    "    \n",
    "    data = pd.read_csv(filename)\n",
    "    data_labels = data['Label']\n",
    "    data_features = data[['Feature_1', 'Feature_3', 'Feature_4', 'Feature_5']]\n",
    "    #this transforms the data so there are negatives\n",
    "#     data_features = data_features.apply(lambda x:x+10000000)\n",
    "    data_features = data_features.abs()\n",
    "    \n",
    "    accuracy = 0\n",
    "    modelKFolds = MultinomialNB()\n",
    "\n",
    "    train_scores = []\n",
    "    test_scores = []\n",
    "\n",
    "    kf = KFold(n_splits=10)\n",
    "    X = np.array(data_features)\n",
    "    print X\n",
    "    Y = np.array(data_labels)\n",
    "    print Y\n",
    "    for train, test in kf.split(X):\n",
    "        x_train, y_train = X[train], Y[train]\n",
    "        x_test, y_test = X[test], Y[test]\n",
    "        \n",
    "        modelKFolds.fit(x_train, y_train)\n",
    "        y_pred = modelKFolds.predict(x_test)\n",
    "        score = metrics.accuracy_score(y_test, y_pred)\n",
    "        accuracy += score\n",
    "    \n",
    "    \n",
    "    print score\n",
    "    return modelKFolds   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(C, row):\n",
    "    row = row.reshape(1, -1)\n",
    "    prediction = C.predict(row)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "def predict_file(C, feature_test_filename, predict_test_filename):\n",
    "    test_data = pd.read_csv(feature_test_filename)\n",
    "    with open(predict_test_filename, 'w') as writeFile:\n",
    "        writer = csv.writer(writeFile) \n",
    "        data_features = test_data[['Feature_1', 'Feature_3', 'Feature_4', 'Feature_5']]\n",
    "        writer.writerow(['Feature_1', 'Feature_3', 'Feature_4', 'Feature_5', 'Label'])\n",
    "        X = np.array(data_features)\n",
    "        line = 0\n",
    "        while (line < 2400):\n",
    "            row = X[line]\n",
    "            prediction = predict(C, row)\n",
    "            row = np.append(row, prediction)\n",
    "            writer.writerow(row)\n",
    "            line += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After writing these methods, I then called train on the training set and predict on the test set with the new predictions included. The training set got an accuracy of 0.69 which is far improved from the initial 0.608 I was getting at the start. The predict_file method also generated a new file with the labels in it which I will be turning in!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7430.14  2453.33    19.     123.  ]\n",
      " [11256.4   4220.      18.     216.  ]\n",
      " [13093.    2880.      30.     234.  ]\n",
      " ...\n",
      " [15793.5   9819.      44.     338.  ]\n",
      " [ 8787.16  3470.08    92.     163.  ]\n",
      " [ 8322.4   2592.59    83.     128.  ]]\n",
      "[0 0 0 ... 1 0 0]\n",
      "0.6928571428571428\n"
     ]
    }
   ],
   "source": [
    "C = train(\"hw1_trainingset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_file(C, \"hw1_testset.csv\", \"hw1_testset_pred.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
